{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mimg\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "#tensorflow\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.applications import mobilenet_v2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, BatchNormalization, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "seed_number = 24\n",
    "tf.random.set_seed(seed_number)\n",
    "np.random.seed(seed_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../spoof/\"\n",
    "input_dir = os.path.join(root,\"data\")\n",
    "train_dir = os.path.join(input_dir, 'train')\n",
    "val_dir = os.path.join(input_dir, 'val')\n",
    "test_dir = os.path.join(input_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = [dir for dir in sorted(os.listdir(input_dir)) if os.path.isdir(os.path.join(input_dir, dir))]\n",
    "label_name = [subdir for subdir in sorted(os.listdir(train_dir)) if os.path.isdir(os.path.join(train_dir, subdir))]\n",
    "\n",
    "# информация о папках\n",
    "print(f\"Main directories\\t: {os.listdir(root)}\")\n",
    "print(f\"Dataset sub-directories\\t: {dataset_dir}\")\n",
    "print(f\"Train set directory\\t: {label_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем validation set\n",
    "def val_make (source, dest):\n",
    "    files = os.listdir(source)\n",
    "    for f in files:\n",
    "        if np.random.rand(1) < 0.3:\n",
    "            shutil.move(source + '/'+ f, dest + '/'+ f)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_make(train_dir + \"/spoof\", val_dir + \"/spoof\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_make(train_dir + \"/real\", val_dir + \"/real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_dict = {'train': train_dir, 'val': val_dir, 'test': test_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_count, img_disp, set_length  = {}, {}, {}\n",
    "\n",
    "for key, val in dir_dict.items():\n",
    "    case_count[key] = {}\n",
    "    img_disp[key] = {}\n",
    "    set_count = 0\n",
    "    \n",
    "    for label in label_name:\n",
    "        label_list = list(sorted(glob.glob(os.path.join(val, label, \"*.png\"))))\n",
    "        if len(label_list) == 0:\n",
    "          continue\n",
    "\n",
    "        case_count[key][label] = len(label_list)\n",
    "        set_count += len(label_list)\n",
    "        \n",
    "        select_img_id = np.random.randint(len(label_list)-1)\n",
    "        # print(select_img_id)\n",
    "        img_disp[key][label] = label_list[select_img_id]\n",
    "        \n",
    "    set_length[key] = set_count\n",
    "\n",
    "case_count_df = pd.DataFrame(case_count)\n",
    "img_disp_df = pd.DataFrame(img_disp)\n",
    "print(f\"Dataset summary:\\n\\n{case_count_df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate data generator for training procedure\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range = 20,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.15,\n",
    "                                   zoom_range = 0.15,\n",
    "                                   horizontal_flip = True,\n",
    "                                   fill_mode=\"nearest\",\n",
    "                                  validation_split = 0.2)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#характиристики датасета\n",
    "train_batch_size = 32\n",
    "val_batch_size = 32\n",
    "flow_from_directory = 224\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(train_dir,\n",
    "                                              batch_size = train_batch_size,\n",
    "                                              class_mode = 'binary',\n",
    "                                              target_size = (img_width, img_height),\n",
    "                                              seed = seed_number)\n",
    "\n",
    "val_gen = val_datagen.flow_from_directory(val_dir,\n",
    "                                          batch_size = val_batch_size,\n",
    "                                          class_mode = 'binary',\n",
    "                                          target_size = (img_width, img_height),\n",
    "                                          seed = seed_number)\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(input_dir,\n",
    "                                              batch_size = 1,\n",
    "                                              class_mode = None,\n",
    "                                              classes=['test'],\n",
    "                                              target_size = (img_width, img_height),\n",
    "                                              seed = seed_number,\n",
    "                                              shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train set batch shape\\t: {next(train_gen)[0].shape}')\n",
    "print(f'Val set batch shape\\t: {next(val_gen)[0].shape}')\n",
    "print(f'Test set batch shape\\t: {next(test_gen)[0].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загружаем MobileNetV2 (она «легче» vvg16)\n",
    "pretrain_net = mobilenet_v2.MobileNetV2(input_shape = (img_width, img_height, 3),\n",
    "                                        include_top = False,\n",
    "                                        weights = 'imagenet')\n",
    "\n",
    "freeze_before = None \n",
    "if freeze_before:\n",
    "    for layer in pretrain_net.layers:\n",
    "        if layer.name == freeze_before:\n",
    "            break\n",
    "        else:\n",
    "            layer.trainable = False    \n",
    "print(pretrain_net.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# дополняем слоями\n",
    "x = pretrain_net.output\n",
    "x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "x = Dropout(rate=0.2, name='extra_dropout1')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1, activation='sigmoid', name='classifier')(x)\n",
    "\n",
    "model = Model(inputs=pretrain_net.input, outputs=x, name='mobilenetv2_spoof')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 15  # обычно после 12 эпохи ничего не изменяется\n",
    "learning_rate = 5e-5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#компилируем модель\n",
    "model.compile(optimizer = Adam(lr=learning_rate),\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определяем веса классов\n",
    "train_length = len(train_gen.classes)\n",
    "\n",
    "weight0 = train_length / case_count_df['train'][label_name[0]] * (1 / len(label_name))\n",
    "weight1 = train_length / case_count_df['train'][label_name[1]] * (1 / len(label_name))\n",
    "class_weight = {0: weight0, 1: weight1}\n",
    "\n",
    "print(f\"Class weight\\t: {class_weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plateau_scheduler = ReduceLROnPlateau(factor=0.2, patience=3, verbose=1, \n",
    "                                      min_delta= 0.005, min_lr=5e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_gen,\n",
    "                    epochs = num_epochs,\n",
    "                    steps_per_epoch = set_length['train'] // train_batch_size,\n",
    "                    validation_data = val_gen,\n",
    "                    validation_steps = 1,\n",
    "                    callbacks = [plateau_scheduler],\n",
    "                    class_weight=class_weight)\n",
    "\n",
    "history_df = pd.DataFrame.from_dict(history.history)\n",
    "history_df.to_csv(os.path.join(root, \"history_14_10.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = history.history['acc']\n",
    "val_accuracy = history.history['val_acc']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(train_accuracy))\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "# точность\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, train_accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['train', 'val'], loc='lower right')\n",
    "\n",
    "# потери\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs, train_loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_model_spoof')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(test_gen,verbose=1,steps=len(test_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = np.argmax(prediction,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=test_gen.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame({\"file\":filenames,\"pred\":prediction[:,0]} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_excel(\"output.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
